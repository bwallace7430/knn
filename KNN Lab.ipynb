{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "DVL7_bgmIAPR"
         },
         "source": [
            "# K-Nearest Neighbor Lab\n",
            "Read over the sklearn info on [nearest neighbor learners](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification)\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {
            "id": "6ZbYjZZZ_yLV"
         },
         "outputs": [],
         "source": [
            "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "from scipy.io import arff\n",
            "import matplotlib.pyplot as plt\n",
            "from sklearn.model_selection import train_test_split"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 1 K-Nearest Neighbor (KNN) algorithm\n",
            "\n",
            "### 1.1 (15%) Basic KNN Classification\n",
            "\n",
            "Learn the [Glass data set](https://archive.ics.uci.edu/dataset/42/glass+identification) using [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) with default parameters.\n",
            "- Randomly split your data into train/test.  Anytime we don't tell you specifics (such as what percentage is train vs test) choose your own reasonable values\n",
            "- Give typical train and test set accuracies after running with different random splits\n",
            "- Print the output probabilities for a test set (predict_proba)\n",
            "- Try it with different p values (Minkowskian exponent) and discuss any differences"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.883721</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.991228</td><td style=\"text-align: right;\">       0.972093</td><td style=\"text-align: right;\">        1</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.4 0.6]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.2 0.8 0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.930233</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.991813</td><td style=\"text-align: right;\">       0.981395</td><td style=\"text-align: right;\">      1.2</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.6 0.4 0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.2 0.8]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.2 0.8 0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.4 0.6 0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.986047</td><td style=\"text-align: right;\">      1.4</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.2 0.8]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.2 0.8 0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.930233</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.930233</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.990058</td><td style=\"text-align: right;\">       0.967442</td><td style=\"text-align: right;\">      1.6</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.2 0.8 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.2 0.8]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.2 0.8 0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.4 0.6 0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.906977</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.906977</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.991228</td><td style=\"text-align: right;\">       0.969767</td><td style=\"text-align: right;\">      1.8</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.8 0.2 0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.2 0.8 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.2 0.8]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.986047</td><td style=\"text-align: right;\">        2</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.8 0.2 0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.4 0.6]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]]\n"
               ]
            }
         ],
         "source": [
            "from IPython.display import HTML, display\n",
            "from tabulate import tabulate\n",
            "\n",
            "# Learn the glass data\n",
            "glass_df = pd.read_csv(\"glass.data\")\n",
            "\n",
            "#extract features X and target variables y\n",
            "X_glass = glass_df.drop('type', axis=1)\n",
            "y_glass = glass_df['type']\n",
            "\n",
            "clf = KNeighborsClassifier()\n",
            "\n",
            "def analyze_model(clf: KNeighborsClassifier, p_value):\n",
            "    table = []\n",
            "    avg_test_acc = 0\n",
            "    avg_train_acc = 0\n",
            "\n",
            "    clf.set_params(p=p_value)\n",
            "    for i in range (0,10):\n",
            "        X_train, X_test, y_train, y_test = train_test_split(X_glass, y_glass, test_size=0.2, shuffle=True)\n",
            "        clf.fit(X_train, y_train) \n",
            "        \n",
            "        table.append([i+1, clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "        avg_train_acc += clf.score(X_train, y_train)\n",
            "        avg_test_acc += clf.score(X_test, y_test)\n",
            "        \n",
            "    avg_train_acc = avg_train_acc/10\n",
            "    avg_test_acc = avg_test_acc/10\n",
            "\n",
            "    #print averages\n",
            "    table.append([\"Average\", avg_train_acc, avg_test_acc, p_value])\n",
            "    headers = [\"Trial\", \"Training Accuracy\", \"Test Accuracy\", \"P_Value\"]\n",
            "    display(HTML(tabulate(table, headers=headers, tablefmt='html')))\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_glass, y_glass, test_size=0.2, shuffle=True)\n",
            "clf.fit(X_train, y_train) \n",
            "\n",
            "analyze_model(clf, 1.0)\n",
            "clf.set_params(p=1.0)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.2)\n",
            "clf.set_params(p=1.2)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.4)\n",
            "clf.set_params(p=1.4)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.6)\n",
            "clf.set_params(p=1.6)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.8)\n",
            "clf.set_params(p=1.8)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 2.0)\n",
            "clf.set_params(p=2.0)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Discussion: The test accuracies were generally highest with a Minkowskian exponent of around 1.0 or 1.2. In the tests that I ran above, the average test set accuracy for a Minkowskian exponent of 1.0 was 0.988372, while for an exponent of 1.2 it was 0.97907. This makes sense because the Minkowskian exponent is a metric that shifts how the distance is measured, with 1.0 being Manhatten distance (which is generally more robust to noise), and 2.0 being Euclidean distance, which gives extra weight to outliers and noise, and so is not as robust. The output probabilities were also interesting to compare. There were often split output probabilities that two or three of the models would agree on, while the others would not. My hypothesis is that this is just a question of how the math boils down for each measurement of distance. Because the Minkowskian exponent is different for each model, there will naturally be some measurements of distance that will turn out differently for some models than for others."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "9vWiTdlbR2Xh"
         },
         "source": [
            "## 2 KNN Classification with normalization and distance weighting\n",
            "\n",
            "Use the [magic telescope](https://axon.cs.byu.edu/data/uci_class/MagicTelescope.arff) dataset\n",
            "\n",
            "### 2.1 (5%) - Without Normalization or Distance Weighting\n",
            "- Do random 80/20 train/test splits each time\n",
            "- Run with k=3 and *without* distance weighting and *without* normalization\n",
            "- Show train and test set accuracy"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {
            "id": "4SSoasDQSKXb"
         },
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">           0.887027</td><td style=\"text-align: right;\">       0.793638</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Learn magic telescope data\n",
            "telescope_data = arff.loadarff('telescope.arff')\n",
            "telescope_df = pd.DataFrame(telescope_data[0])\n",
            "\n",
            "X_telescope = telescope_df.drop('class:', axis=1)\n",
            "y_telescope = telescope_df['class:']\n",
            "y_telescope = pd.get_dummies(y_telescope)\n",
            "\n",
            "clf = KNeighborsClassifier(weights='uniform', n_neighbors=3)\n",
            "\n",
            "table = []\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_telescope, y_telescope, test_size=0.2, shuffle=True)\n",
            "clf.fit(X_train, y_train)\n",
            "        \n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "headers = [\"Training Accuracy\", \"Test Accuracy\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discussion* This model had a fairly low test accuracy score of around .8, which is not surprising to me. Our k value is fairly low, and we are running this without distance weighting, which means that the three closest points are being considered equally, regardless of how far away they may be. Our data is also not normalized. This means that large-scale numerical features (such as the attribute fDist, which ranges into the hundreds) have a very significant effect on our calculations of distance, while our small-scale features have next to no effect on distance. This means that if a small-scale feature is more indicative than a large-scale feature, it will still not be considered in the classification of a point, because the nearest neighbors will be those that have the smallest distance in the large-scale features only."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 2.2 (10%) With Normalization\n",
            "- Try it with k=3 without distance weighting but *with* normalization of input features.  You may use any reasonable normalization approach (e.g. standard min-max normalization between 0-1, z-transform, etc.)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">           0.900894</td><td style=\"text-align: right;\">       0.827287</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "from sklearn.preprocessing import MinMaxScaler\n",
            "\n",
            "# Train/Predict with normalization\n",
            "scaler = MinMaxScaler()\n",
            "X_normalized = scaler.fit_transform(X_telescope)\n",
            "\n",
            "table = []\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_telescope, test_size=0.2, shuffle=True)\n",
            "clf.fit(X_train, y_train)\n",
            "        \n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "headers = [\"Training Accuracy\", \"Test Accuracy\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discuss the results of using normalized data vs. unnormalized data* Normalizing the data did increase the test set accuracy from around .8 to about .83. However, this is a much smaller improvement than I would have expected, given how large some of the features in the telescope are measured. My assumption is that the improvement was relatively small because the originally large-scaled features in the dataset were highly indicative of class, or because the combination of the small-scaled features and large-scaled features still led to the same nearest neighbors being picked. This means that even when the small-scaled features got a more even influence on the distance between points, it did not greatly change the way that the distances were calculated, and the nearest neighbors chosen resulted in about the same accuracy of classification."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 2.3 (10%) With Distance Weighting\n",
            "- Try it with k=3 and with distance weighting *and* normalization"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">       0.830705</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "#Train/Predict with normalization and distance weighting\n",
            "table = []\n",
            "clf.set_params(n_neighbors=3, weights='distance')\n",
            "clf.fit(X_train, y_train)\n",
            "        \n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "headers = [\"Training Accuracy\", \"Test Accuracy\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Comparison and Discussion: The model is getting the exact same accuracy as the model with the normalization but without this distance weighting. Although it is possible that the points classified correctly are different points from those classified correctly by the model that just used normalization, I find this unlikely. The models are k=3 models, which means there would need to be at least 2 neighbors that contribute to any misclassification. Unless there is a fairly large difference in the distances of the misclassifying neighbors and the distance of any correctly classifying neighbor, with the misclassifying neighbors being much further from the point of interest than the correctly classifying neighbor, the misclassifying points will have more influence, as there are more of them at a roughly similar distance as the correctly classifying point."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 2.4 (10%) Different k Values\n",
            "- Using your normalized data with distance weighting, create one graph with classification accuracy on the test set on the y-axis and k values on the x-axis.\n",
            "- Use values of k from 1 to 15.  Use the same train/test split for each. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Calculate and Graph classification accuracy vs k values\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_telescope, test_size=0.2, shuffle=True)\n",
            "\n",
            "accuracies = []\n",
            "k_values = []\n",
            "\n",
            "for i in range(0, 15):\n",
            "    k = i + 1\n",
            "    clf.set_params(n_neighbors=k, weights='distance')\n",
            "    clf.fit(X_train, y_train)\n",
            "    k_values.append(k)\n",
            "    accuracies.append(clf.score(X_test, y_test))\n",
            "\n",
            "plt.plot(k_values, accuracies, label='K-Value vs Accuracy')\n",
            "plt.title(\"K-Value vs Accuracy\")\n",
            "plt.xlabel(\"K-Value\")\n",
            "plt.ylabel(\"Accuracy\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discussion*: The accuracy generally improved as more nearest neighbors were taken into account, with the k=15 model getting the highest accuracy score of around .848. However, this is still a fairly low score, which can be explained in a couple different ways. The dataset could have a feature or multiple features that are not indicative of class. These features will still be taken into account in equal measure with the features that are indicative of class, which could cause dissimilar points to be nearest neighbors with one another, leading to misclassification. Another factor in the low accuracy could be a large number of noisy datapoints or outliers, which can act as misclassifying nearest neighbors that contribute to a low classification accuracy for the model as an overall whole."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "SIRG42TgSR4x"
         },
         "source": [
            "## 3 KNN Regression with normalization and distance weighting\n",
            "\n",
            "Use the [sklean KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) on the [housing price prediction](https://axon.cs.byu.edu/data/uci_regression/housing.arff) problem.  \n",
            "### 3.1 (5%) Ethical Data\n",
            "Note this data set has an example of an inappropriate input feature which we discussed.  State which feature is inappropriate and discuss why."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discuss the innapropriate feature*: The feature B is an inappropriate input feature that measures the proportion of black people that live in the area of the house of interest. This feature is inappropriate for a number of reasons, and can have extremely negative impacts in the ethicality of the model. The feature is inappropriate because it may cause the model to pick up on and adopt racist beliefs or methodologies that are unethical and should not have any practical influence on the price of a house. If a model trained on this feature is used in an official capacity, it has the potential to increase divisions of racism and classism, and could have immoral effects on the socio-economic makeup of an area due to race."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 3.2 (15%) - KNN Regression \n",
            "- Do random 80/20 train/test splits each time\n",
            "- Run with k=3\n",
            "- Print the score (coefficient of determination) and Mean Absolute Error (MAE) for the train and test set for the cases of\n",
            "  - No input normalization and no distance weighting\n",
            "  - Normalization and no distance weighting\n",
            "  - Normalization and distance weighting\n",
            "- Normalize inputs features where needed but do not normalize the output"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {
            "id": "KBGUn43ASiXW"
         },
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Type                          </th><th style=\"text-align: right;\">  Train Score</th><th style=\"text-align: right;\">  Test Score</th><th style=\"text-align: right;\">  Training MAE</th><th style=\"text-align: right;\">  Testing MAE</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>No Normalization or Weighting </td><td style=\"text-align: right;\">     0.788569</td><td style=\"text-align: right;\">    0.526006</td><td style=\"text-align: right;\">       2.81947</td><td style=\"text-align: right;\">      4.40784</td></tr>\n",
                     "<tr><td>Normalization and No Weighting</td><td style=\"text-align: right;\">     0.885043</td><td style=\"text-align: right;\">    0.781501</td><td style=\"text-align: right;\">       2.03391</td><td style=\"text-align: right;\">      2.79575</td></tr>\n",
                     "<tr><td>Normalization and Weighting   </td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">    0.783177</td><td style=\"text-align: right;\">       0      </td><td style=\"text-align: right;\">      2.59759</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "from sklearn.metrics import mean_absolute_error\n",
            "\n",
            "# Learn and experiment with housing price prediction data\n",
            "housing_data = arff.loadarff('housing.arff')\n",
            "housing_df = pd.DataFrame(housing_data[0])\n",
            "X_housing = housing_df.drop('MEDV', axis=1)\n",
            "y_housing = housing_df['MEDV']\n",
            "\n",
            "table = []\n",
            "\n",
            "def train_model(type, X, y, table:list, param='uniform') -> list:\n",
            "    reg = KNeighborsRegressor(n_neighbors=3, weights=param)\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
            "    reg.fit(X_train, y_train)\n",
            "    y_train_pred = reg.predict(X_train)\n",
            "    y_test_pred = reg.predict(X_test)\n",
            "    table.append([type, reg.score(X_train, y_train), reg.score(X_test, y_test), mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)])\n",
            "    return table\n",
            "\n",
            "table = train_model(\"No Normalization or Weighting\", X_housing, y_housing, table)\n",
            "\n",
            "scaler = MinMaxScaler()\n",
            "X_normalized = scaler.fit_transform(X_housing)\n",
            "table = train_model(\"Normalization and No Weighting\", X_normalized, y_housing, table)\n",
            "\n",
            "table = train_model(\"Normalization and Weighting\", X_normalized, y_housing, table, 'distance')\n",
            "\n",
            "\n",
            "headers = [\"Type\", \"Train Score\", \"Test Score\", \"Training MAE\", \"Testing MAE\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discuss your results*: The normalization and distance weighting helped dramatically with this dataset, much as I had expected from the earlier telescope dataset. The original test score was around .46. After normalization, the score had improved to .76, and after including distance weighting the score had improved again to .84. In the final model, the testing mean absolute error was only 2.388. Although this error is not insignificant, it is around half of the mean absolute error from the test set in the first model, which was about 4.78. This is likely because there were large-scale features that influenced the set dramatically before normalization. "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 3.3 (10%)  Different k Values\n",
            "- Using housing with normalized data and distance weighting, create one graph with MAE on the test set on the y-axis and k values on the x-axis\n",
            "- Use values of k from 1 to 15.  Use the same train/test split for each. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Learn and graph for different k values\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_housing, test_size=0.2, shuffle=True)\n",
            "reg = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
            "\n",
            "accuracies = []\n",
            "k_values = []\n",
            "\n",
            "for i in range(0, 15):\n",
            "    k = i + 1\n",
            "    reg.set_params(n_neighbors=k)\n",
            "    reg.fit(X_train, y_train)\n",
            "    y_test_pred = reg.predict(X_test)\n",
            "    k_values.append(k)\n",
            "    accuracies.append(mean_absolute_error(y_test, y_test_pred))\n",
            "\n",
            "plt.plot(k_values, accuracies, label='K-Value vs. MAE')\n",
            "plt.title(\"K-Value vs. MAE\")\n",
            "plt.xlabel(\"K-Value\")\n",
            "plt.ylabel(\"MAE\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Discussion: The MAE generally grew as the value of k grew. It reached a minimum when the k value was around 2 or 3, then grew after that. This makes sense, because the true value of any given point is a continuous value. This means that as points are further and further from the point of interest and are given a say in what the value should be, they will drag the predicted value further and further away from where it should be. This is different from classification, in which points do not become more drastically different the further they are from the point of interest. They may be a different class, but there is no gradient of difference that the points are located on."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 4. (20%) KNN with nominal and real data\n",
            "\n",
            "- Use the [lymph dataset](https://axon.cs.byu.edu/data/uci_class/lymph.arff)\n",
            "- Use a 80/20 split of the data for the training/test set\n",
            "- This dataset has both continuous and nominal attributes \n",
            "- Implement a distance metric which uses Euclidean distance for continuous features and 0/1 distance for nominal. Hints:\n",
            "    - Write your own distance function (e.g. mydist) and use clf = KNeighborsClassifier(metric=mydist)\n",
            "    - Change the nominal features in the data set to integer values since KNeighborsClassifier expects numeric features. I used Label_Encoder on the nominal features.\n",
            "    - Keep a list of which features are nominal which mydist can use to decide which distance measure to use\n",
            "    - There was an occasional bug in SK version 1.3.0 (\"Flags object has no attribute 'c_contiguous'\") that went away when I upgraded to the lastest SK version 1.3.1 \n",
            "- Use your own choice for k and other parameters"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Train Score</th><th style=\"text-align: right;\">  Test Score</th><th style=\"text-align: right;\">  Training MAE</th><th style=\"text-align: right;\">  Testing MAE</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">         0.8</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">     0.266667</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "from sklearn.preprocessing import LabelEncoder\n",
            "# Train/Predict lymph with your own distance metric\n",
            "lymph_data = arff.loadarff('lymph.arff')\n",
            "lymph_df = pd.DataFrame(lymph_data[0])\n",
            "X_lymph = lymph_df.drop('class', axis=1)\n",
            "y_lymph = lymph_df['class']\n",
            "\n",
            "nominal_features = ['lymphatics','block_of_affere', 'bl_of_lymph_c', 'bl_of_lymph_s', 'by_pass', 'extravasates', 'regeneration_of', 'early_uptake_in', 'changes_in_lym', 'defect_in_node', 'changes_in_node', 'changes_in_stru', 'special_forms', 'dislocation_of', 'exclusion_of_no']\n",
            "nominal_indices = []\n",
            "encoder = LabelEncoder()\n",
            "\n",
            "y_lymph = encoder.fit_transform(y_lymph)\n",
            "for feature in nominal_features:\n",
            "    X_lymph[feature] = encoder.fit_transform(X_lymph[feature])\n",
            "    nominal_indices.append(lymph_df.columns.get_loc(feature))\n",
            "\n",
            "    \n",
            "def mydist(point_1, point_2):\n",
            "    distance = 0.0\n",
            "    for i in range(len(point_1)):\n",
            "        if i in nominal_indices:\n",
            "            if (point_1[i] != point_2[i]):\n",
            "                distance += 1\n",
            "        else:\n",
            "            distance += (point_1[i] - point_2[i])**2\n",
            "    finished_euclidean_distance = np.sqrt(distance)\n",
            "    return finished_euclidean_distance\n",
            "    \n",
            "clf = KNeighborsClassifier(metric=mydist, n_neighbors=15, weights='distance')\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_lymph, y_lymph, test_size=0.2, shuffle=True)\n",
            "table = []\n",
            "clf.fit(X_train, y_train)\n",
            "y_test_pred = clf.predict(X_test)\n",
            "y_train_pred = clf.predict(X_train)\n",
            "\n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test), mean_absolute_error(y_train_pred, y_train), mean_absolute_error(y_test_pred, y_test)])\n",
            "\n",
            "headers = [\"Train Score\", \"Test Score\", \"Training MAE\", \"Testing MAE\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Explain your distance metric and discuss your results*"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 5. (Optional 15% extra credit) Code up your own KNN Learner \n",
            "Below is a scaffold you could use if you want. Requirements for this task:\n",
            "- Your model should support the methods shown in the example scaffold below\n",
            "- Use Euclidean distance to decide closest neighbors\n",
            "- Implement both the classification and regression versions\n",
            "- Include optional distance weighting for both algorithms\n",
            "- Run your algorithm on the magic telescope and housing data sets above and discuss and compare your results "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discussion*"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [
            {
               "ename": "IndexError",
               "evalue": "string index out of range",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                  "\u001b[1;32m/Users/josephhenderson/brynne's coding/knn/KNN Lab.ipynb Cell 31\u001b[0m in \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X_telescope, y_telescope)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=98'>99</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(clf\u001b[39m.\u001b[39;49mscore(X_test, y_test)))\n",
                  "\u001b[1;32m/Users/josephhenderson/brynne's coding/knn/KNN Lab.ipynb Cell 31\u001b[0m in \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscore\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     \u001b[39m\"\"\" Return accuracy of model on a given dataset. Must implement own score function.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m \u001b[39m        X (array-like): A 2D numpy array with data, excluding targets\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m \u001b[39m            Mean accuracy of self.predict(X) wrt. y.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m     predictions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m     num_correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, prediction \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(predictions):\n",
                  "\u001b[1;32m/Users/josephhenderson/brynne's coding/knn/KNN Lab.ipynb Cell 31\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m distances \u001b[39m=\u001b[39m []  \u001b[39m# To store (distance, class) for each neighbor\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, train_sample \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     dist \u001b[39m=\u001b[39m calculate_distance(sample, train_sample)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     distances\u001b[39m.\u001b[39mappend((dist, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my\u001b[39m.\u001b[39miloc[i]))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Sort distances and get the k nearest neighbors\u001b[39;00m\n",
                  "\u001b[1;32m/Users/josephhenderson/brynne's coding/knn/KNN Lab.ipynb Cell 31\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(point_1)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(point_1[i]) \u001b[39mis\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m         \u001b[39mif\u001b[39;00m point_1[i] \u001b[39m!=\u001b[39m point_2[i]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m             distance \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/josephhenderson/brynne%27s%20coding/knn/KNN%20Lab.ipynb#X42sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
                  "\u001b[0;31mIndexError\u001b[0m: string index out of range"
               ]
            }
         ],
         "source": [
            "from sklearn.base import BaseEstimator, ClassifierMixin\n",
            "import numpy as np\n",
            "\n",
            "class KNNClassifier(BaseEstimator,ClassifierMixin):\n",
            "    def __init__(self, columntype=[], weight_type='inverse_distance'): ## add parameters here\n",
            "        \n",
            "        \"\"\"\n",
            "        Args:\n",
            "            columntype for each column tells you if continues[real] or if nominal[categoritcal].\n",
            "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
            "        \"\"\"\n",
            "        self.columntype = columntype #Note This won't be needed until part 5\n",
            "        self.weight_type = weight_type\n",
            "        self.X = []\n",
            "        self.y = []\n",
            "\n",
            "    def fit(self, data, labels):\n",
            "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
            "            y (array-like): A 2D numpy array with the training targets\n",
            "        Returns:\n",
            "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
            "        \"\"\"\n",
            "        \n",
            "        self.X = data\n",
            "        self.y = labels\n",
            "        return self\n",
            "    \n",
            "    def predict(self, data):\n",
            "        \"\"\" Predict all classes for a dataset X\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
            "        Returns:\n",
            "            array, shape (n_samples,)\n",
            "                Predicted target values per element in X.\n",
            "        \"\"\"\n",
            "        def calculate_distance(point_1, point_2):\n",
            "            distance = 0\n",
            "            for i in range(len(point_1)):\n",
            "                if type(point_1[i]) is str:\n",
            "                    if point_1[i] != point_2[i]:\n",
            "                        distance += 1\n",
            "                else:\n",
            "                    distance += (point_1[i] - point_2[i])**2\n",
            "            return np.sqrt(distance)\n",
            "        predictions = []\n",
            "        for sample in data:\n",
            "            distances = []  # To store (distance, class) for each neighbor\n",
            "            for i, train_sample in enumerate(self.X):\n",
            "                dist = calculate_distance(sample, train_sample)\n",
            "                distances.append((dist, self.y.iloc[i]))\n",
            "\n",
            "            # Sort distances and get the k nearest neighbors\n",
            "            distances.sort(key=lambda x: x[0])\n",
            "            nearest_neighbors = distances[:self.k]\n",
            "\n",
            "            if self.weight_type == \"inverse_distance\":\n",
            "                # Weighted voting based on inverse distances\n",
            "                class_count = {}\n",
            "                for dist, label in nearest_neighbors:\n",
            "                    if dist == 0:\n",
            "                        weight = float(\"inf\")  # Prevent division by zero\n",
            "                    else:\n",
            "                        weight = 1 / dist\n",
            "                    class_count[label] = class_count.get(label, 0) + weight\n",
            "\n",
            "                predicted_class = max(class_count, key=class_count.get)\n",
            "            else:\n",
            "                # Simple majority voting (no distance weighting)\n",
            "                labels = [neighbor[1] for neighbor in nearest_neighbors]\n",
            "                predicted_class = max(set(labels), key=labels.count)\n",
            "\n",
            "            predictions.append(predicted_class)\n",
            "\n",
            "        return np.array(predictions)\n",
            "\n",
            "    #Returns the Mean score given input data and labels\n",
            "    def score(self, X, y):\n",
            "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with data, excluding targets\n",
            "            y (array-like): A 2D numpy array with targets\n",
            "        Returns:\n",
            "            score : floats\n",
            "                Mean accuracy of self.predict(X) wrt. y.\n",
            "        \"\"\"\n",
            "\n",
            "        predictions = self.predict(X)\n",
            "        num_correct = 0\n",
            "        for i, prediction in enumerate(predictions):\n",
            "            if prediction == self.y[i]:\n",
            "                num_correct += 1\n",
            "        return num_correct/len(predictions)\n",
            "\n",
            "clf = KNNClassifier()\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_telescope, y_telescope)\n",
            "clf.fit(X_train, y_train)\n",
            "print(str(clf.score(X_test, y_test)))\n"
         ]
      }
   ],
   "metadata": {
      "colab": {
         "collapsed_sections": [],
         "name": "lab 1 - perceptron",
         "provenance": []
      },
      "kernelspec": {
         "display_name": "Python 3.10.7 64-bit",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.13"
      },
      "vscode": {
         "interpreter": {
            "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
