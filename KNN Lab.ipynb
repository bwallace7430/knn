{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "DVL7_bgmIAPR"
         },
         "source": [
            "# K-Nearest Neighbor Lab\n",
            "Read over the sklearn info on [nearest neighbor learners](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification)\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {
            "id": "6ZbYjZZZ_yLV"
         },
         "outputs": [],
         "source": [
            "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "from scipy.io import arff\n",
            "import matplotlib.pyplot as plt\n",
            "from sklearn.model_selection import train_test_split"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 1 K-Nearest Neighbor (KNN) algorithm\n",
            "\n",
            "### 1.1 (15%) Basic KNN Classification\n",
            "\n",
            "Learn the [Glass data set](https://archive.ics.uci.edu/dataset/42/glass+identification) using [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) with default parameters.\n",
            "- Randomly split your data into train/test.  Anytime we don't tell you specifics (such as what percentage is train vs test) choose your own reasonable values\n",
            "- Give typical train and test set accuracies after running with different random splits\n",
            "- Print the output probabilities for a test set (predict_proba)\n",
            "- Try it with different p values (Minkowskian exponent) and discuss any differences"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.992398</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">        1</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.6 0.4 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.2 0.8 0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.2 0.8 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.976608</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.990643</td><td style=\"text-align: right;\">       0.983721</td><td style=\"text-align: right;\">      1.2</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.6 0.4 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.2 0.8 0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.2 0.8 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.8 0.2 0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.991228</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">      1.4</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.8 0.2 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.4 0.6 0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.2 0.8 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.8 0.2 0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.2 0.8 0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.97076 </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.930233</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.987135</td><td style=\"text-align: right;\">       0.969767</td><td style=\"text-align: right;\">      1.6</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.4 0.6 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.2 0.8 0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.2 0.8 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.8 0.2 0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.2 0.8 0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.988889</td><td style=\"text-align: right;\">       0.967442</td><td style=\"text-align: right;\">      1.8</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.6 0.4 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.4 0.6 0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.4 0.6 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.8 0.2 0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.930233</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.930233</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.976608</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.989474</td><td style=\"text-align: right;\">       0.972093</td><td style=\"text-align: right;\">        2</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.4 0.6 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.4 0.6 0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.2 0.8 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.8 0.2 0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.2 0.8 0.  0.  0. ]]\n"
               ]
            }
         ],
         "source": [
            "from IPython.display import HTML, display\n",
            "from tabulate import tabulate\n",
            "\n",
            "# Learn the glass data\n",
            "glass_df = pd.read_csv(\"glass.data\")\n",
            "\n",
            "#extract features X and target variables y\n",
            "X_glass = glass_df.drop('type', axis=1)\n",
            "y_glass = glass_df['type']\n",
            "\n",
            "clf = KNeighborsClassifier()\n",
            "\n",
            "def analyze_model(clf: KNeighborsClassifier, p_value):\n",
            "    table = []\n",
            "    avg_test_acc = 0\n",
            "    avg_train_acc = 0\n",
            "\n",
            "    clf.set_params(p=p_value)\n",
            "    for i in range (0,10):\n",
            "        X_train, X_test, y_train, y_test = train_test_split(X_glass, y_glass, test_size=0.2, shuffle=True)\n",
            "        clf.fit(X_train, y_train) \n",
            "        \n",
            "        table.append([i+1, clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "        avg_train_acc += clf.score(X_train, y_train)\n",
            "        avg_test_acc += clf.score(X_test, y_test)\n",
            "        \n",
            "    avg_train_acc = avg_train_acc/10\n",
            "    avg_test_acc = avg_test_acc/10\n",
            "\n",
            "    #print averages\n",
            "    table.append([\"Average\", avg_train_acc, avg_test_acc, p_value])\n",
            "    headers = [\"Trial\", \"Training Accuracy\", \"Test Accuracy\", \"P_Value\"]\n",
            "    display(HTML(tabulate(table, headers=headers, tablefmt='html')))\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_glass, y_glass, test_size=0.2, shuffle=True)\n",
            "clf.fit(X_train, y_train) \n",
            "\n",
            "analyze_model(clf, 1.0)\n",
            "clf.set_params(p=1.0)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.2)\n",
            "clf.set_params(p=1.2)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.4)\n",
            "clf.set_params(p=1.4)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.6)\n",
            "clf.set_params(p=1.6)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.8)\n",
            "clf.set_params(p=1.8)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 2.0)\n",
            "clf.set_params(p=2.0)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Discussion: The test accuracies were generally highest with a Minkowskian exponent of around 1.0 or 1.2. In the tests that I ran above, the average test set accuracy for a Minkowskian exponent of 1.0 was 0.988372, while for an exponent of 1.2 it was 0.97907. This makes sense because the Minkowskian exponent is a metric that shifts how the distance is measured, with 1.0 being Manhatten distance (which is generally more robust to noise), and 2.0 being Euclidean distance, which gives extra weight to outliers and noise, and so is not as robust. The output probabilities were also interesting to compare. There were often split output probabilities that two or three of the models would agree on, while the others would not. My hypothesis is that this is just a question of how the math boils down for each measurement of distance. Because the Minkowskian exponent is different for each model, there will naturally be some measurements of distance that will turn out differently for some models than for others."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "9vWiTdlbR2Xh"
         },
         "source": [
            "## 2 KNN Classification with normalization and distance weighting\n",
            "\n",
            "Use the [magic telescope](https://axon.cs.byu.edu/data/uci_class/MagicTelescope.arff) dataset\n",
            "\n",
            "### 2.1 (5%) - Without Normalization or Distance Weighting\n",
            "- Do random 80/20 train/test splits each time\n",
            "- Run with k=3 and *without* distance weighting and *without* normalization\n",
            "- Show train and test set accuracy"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {
            "id": "4SSoasDQSKXb"
         },
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">           0.886041</td><td style=\"text-align: right;\">       0.787592</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Learn magic telescope data\n",
            "telescope_data = arff.loadarff('telescope.arff')\n",
            "telescope_df = pd.DataFrame(telescope_data[0])\n",
            "\n",
            "X_telescope = telescope_df.drop('class:', axis=1)\n",
            "y_telescope = telescope_df['class:']\n",
            "y_telescope = pd.get_dummies(y_telescope)\n",
            "\n",
            "clf = KNeighborsClassifier(weights='uniform', n_neighbors=3)\n",
            "\n",
            "table = []\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_telescope, y_telescope, test_size=0.2, shuffle=True)\n",
            "clf.fit(X_train, y_train)\n",
            "        \n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "headers = [\"Training Accuracy\", \"Test Accuracy\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discussion* This model had a fairly low test accuracy score of around .8, which is not surprising to me. Our k value is fairly low, and we are running this without distance weighting, which means that the three closest points are being considered equally, regardless of how far away they may be. Our data is also not normalized. This means that large-scale numerical features (such as the attribute fDist, which ranges into the hundreds) have a very significant effect on our calculations of distance, while our small-scale features have next to no effect on distance. This means that if a small-scale feature is more indicative than a large-scale feature, it will still not be considered in the classification of a point, because the nearest neighbors will be those that have the smallest distance in the large-scale features only."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 2.2 (10%) With Normalization\n",
            "- Try it with k=3 without distance weighting but *with* normalization of input features.  You may use any reasonable normalization approach (e.g. standard min-max normalization between 0-1, z-transform, etc.)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">           0.900105</td><td style=\"text-align: right;\">       0.829653</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "from sklearn.preprocessing import MinMaxScaler\n",
            "\n",
            "# Train/Predict with normalization\n",
            "scaler = MinMaxScaler()\n",
            "X_normalized = scaler.fit_transform(X_telescope)\n",
            "\n",
            "table = []\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_telescope, test_size=0.2, shuffle=True)\n",
            "clf.fit(X_train, y_train)\n",
            "        \n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "headers = [\"Training Accuracy\", \"Test Accuracy\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discuss the results of using normalized data vs. unnormalized data* Normalizing the data did increase the test set accuracy from around .8 to about .83. However, this is a much smaller improvement than I would have expected, given how large some of the features in the telescope are measured. My assumption is that the improvement was relatively small because the originally large-scaled features in the dataset were highly indicative of class, or because the combination of the small-scaled features and large-scaled features still led to the same nearest neighbors being picked. This means that even when the small-scaled features got a more even influence on the distance between points, it did not greatly change the way that the distances were calculated, and the nearest neighbors chosen resulted in about the same accuracy of classification."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 2.3 (10%) With Distance Weighting\n",
            "- Try it with k=3 and with distance weighting *and* normalization"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">       0.832019</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "#Train/Predict with normalization and distance weighting\n",
            "table = []\n",
            "clf.set_params(n_neighbors=3, weights='distance')\n",
            "clf.fit(X_train, y_train)\n",
            "        \n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "headers = [\"Training Accuracy\", \"Test Accuracy\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Comparison and Discussion: The model is getting the exact same accuracy as the model with the normalization but without this distance weighting. Although it is possible that the points classified correctly are different points from those classified correctly by the model that just used normalization, I find this unlikely. The models are k=3 models, which means there would need to be at least 2 neighbors that contribute to any misclassification. Unless there is a fairly large difference in the distances of the misclassifying neighbors and the distance of any correctly classifying neighbor, with the misclassifying neighbors being much further from the point of interest than the correctly classifying neighbor, the misclassifying points will have more influence, as there are more of them at a roughly similar distance as the correctly classifying point."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 2.4 (10%) Different k Values\n",
            "- Using your normalized data with distance weighting, create one graph with classification accuracy on the test set on the y-axis and k values on the x-axis.\n",
            "- Use values of k from 1 to 15.  Use the same train/test split for each. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Calculate and Graph classification accuracy vs k values\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_telescope, test_size=0.2, shuffle=True)\n",
            "\n",
            "accuracies = []\n",
            "k_values = []\n",
            "\n",
            "for i in range(0, 15):\n",
            "    k = i + 1\n",
            "    clf.set_params(n_neighbors=k, weights='distance')\n",
            "    clf.fit(X_train, y_train)\n",
            "    k_values.append(k)\n",
            "    accuracies.append(clf.score(X_test, y_test))\n",
            "\n",
            "plt.plot(k_values, accuracies, label='K-Value vs Accuracy')\n",
            "plt.title(\"K-Value vs Accuracy\")\n",
            "plt.xlabel(\"K-Value\")\n",
            "plt.ylabel(\"Accuracy\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discussion*: The accuracy generally improved as more nearest neighbors were taken into account, with the k=15 model getting the highest accuracy score of around .848. However, this is still a fairly low score, which can be explained in a couple different ways. The dataset could have a feature or multiple features that are not indicative of class. These features will still be taken into account in equal measure with the features that are indicative of class, which could cause dissimilar points to be nearest neighbors with one another, leading to misclassification. Another factor in the low accuracy could be a large number of noisy datapoints or outliers, which can act as misclassifying nearest neighbors that contribute to a low classification accuracy for the model as an overall whole."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "SIRG42TgSR4x"
         },
         "source": [
            "## 3 KNN Regression with normalization and distance weighting\n",
            "\n",
            "Use the [sklean KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) on the [housing price prediction](https://axon.cs.byu.edu/data/uci_regression/housing.arff) problem.  \n",
            "### 3.1 (5%) Ethical Data\n",
            "Note this data set has an example of an inappropriate input feature which we discussed.  State which feature is inappropriate and discuss why."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discuss the innapropriate feature*: The feature B is an inappropriate input feature that measures the proportion of black people that live in the area of the house of interest. This feature is inappropriate for a number of reasons, and can have extremely negative impacts in the ethicality of the model. The feature is inappropriate because it may cause the model to pick up on and adopt racist beliefs or methodologies that are unethical and should not have any practical influence on the price of a house. If a model trained on this feature is used in an official capacity, it has the potential to increase divisions of racism and classism, and could have immoral effects on the socio-economic makeup of an area due to race."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 3.2 (15%) - KNN Regression \n",
            "- Do random 80/20 train/test splits each time\n",
            "- Run with k=3\n",
            "- Print the score (coefficient of determination) and Mean Absolute Error (MAE) for the train and test set for the cases of\n",
            "  - No input normalization and no distance weighting\n",
            "  - Normalization and no distance weighting\n",
            "  - Normalization and distance weighting\n",
            "- Normalize inputs features where needed but do not normalize the output"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {
            "id": "KBGUn43ASiXW"
         },
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Type                          </th><th style=\"text-align: right;\">  Train Score</th><th style=\"text-align: right;\">  Test Score</th><th style=\"text-align: right;\">  Training MAE</th><th style=\"text-align: right;\">  Testing MAE</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>No Normalization or Weighting </td><td style=\"text-align: right;\">     0.775124</td><td style=\"text-align: right;\">    0.501938</td><td style=\"text-align: right;\">       3.04926</td><td style=\"text-align: right;\">      4.13562</td></tr>\n",
                     "<tr><td>Normalization and No Weighting</td><td style=\"text-align: right;\">     0.897895</td><td style=\"text-align: right;\">    0.628995</td><td style=\"text-align: right;\">       1.87987</td><td style=\"text-align: right;\">      3.68235</td></tr>\n",
                     "<tr><td>Normalization and Weighting   </td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">    0.76768 </td><td style=\"text-align: right;\">       0      </td><td style=\"text-align: right;\">      2.93908</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "from sklearn.metrics import mean_absolute_error\n",
            "\n",
            "# Learn and experiment with housing price prediction data\n",
            "housing_data = arff.loadarff('housing.arff')\n",
            "housing_df = pd.DataFrame(housing_data[0])\n",
            "X_housing = housing_df.drop('MEDV', axis=1)\n",
            "y_housing = housing_df['MEDV']\n",
            "\n",
            "table = []\n",
            "\n",
            "def train_model(type, X, y, table:list, param='uniform') -> list:\n",
            "    reg = KNeighborsRegressor(n_neighbors=3, weights=param)\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
            "    reg.fit(X_train, y_train)\n",
            "    y_train_pred = reg.predict(X_train)\n",
            "    y_test_pred = reg.predict(X_test)\n",
            "    table.append([type, reg.score(X_train, y_train), reg.score(X_test, y_test), mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)])\n",
            "    return table\n",
            "\n",
            "table = train_model(\"No Normalization or Weighting\", X_housing, y_housing, table)\n",
            "\n",
            "scaler = MinMaxScaler()\n",
            "X_normalized = scaler.fit_transform(X_housing)\n",
            "table = train_model(\"Normalization and No Weighting\", X_normalized, y_housing, table)\n",
            "\n",
            "table = train_model(\"Normalization and Weighting\", X_normalized, y_housing, table, 'distance')\n",
            "\n",
            "\n",
            "headers = [\"Type\", \"Train Score\", \"Test Score\", \"Training MAE\", \"Testing MAE\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discuss your results*: The normalization and distance weighting helped dramatically with this dataset, much as I had expected from the earlier telescope dataset. The original test score was around .46. After normalization, the score had improved to .76, and after including distance weighting the score had improved again to .84. In the final model, the testing mean absolute error was only 2.388. Although this error is not insignificant, it is around half of the mean absolute error from the test set in the first model, which was about 4.78. This is likely because there were large-scale features that influenced the set dramatically before normalization. "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 3.3 (10%)  Different k Values\n",
            "- Using housing with normalized data and distance weighting, create one graph with MAE on the test set on the y-axis and k values on the x-axis\n",
            "- Use values of k from 1 to 15.  Use the same train/test split for each. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Learn and graph for different k values\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_housing, test_size=0.2, shuffle=True)\n",
            "reg = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
            "\n",
            "accuracies = []\n",
            "k_values = []\n",
            "\n",
            "for i in range(0, 15):\n",
            "    k = i + 1\n",
            "    reg.set_params(n_neighbors=k)\n",
            "    reg.fit(X_train, y_train)\n",
            "    y_test_pred = reg.predict(X_test)\n",
            "    k_values.append(k)\n",
            "    accuracies.append(mean_absolute_error(y_test, y_test_pred))\n",
            "\n",
            "plt.plot(k_values, accuracies, label='K-Value vs. MAE')\n",
            "plt.title(\"K-Value vs. MAE\")\n",
            "plt.xlabel(\"K-Value\")\n",
            "plt.ylabel(\"MAE\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Discussion: The MAE generally grew as the value of k grew. It reached a minimum when the k value was around 2 or 3, then grew after that. This makes sense, because the true value of any given point is a continuous value. This means that as points are further and further from the point of interest and are given a say in what the value should be, they will drag the predicted value further and further away from where it should be. This is different from classification, in which points do not become more drastically different the further they are from the point of interest. They may be a different class, but there is no gradient of difference that the points are located on."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 4. (20%) KNN with nominal and real data\n",
            "\n",
            "- Use the [lymph dataset](https://axon.cs.byu.edu/data/uci_class/lymph.arff)\n",
            "- Use a 80/20 split of the data for the training/test set\n",
            "- This dataset has both continuous and nominal attributes \n",
            "- Implement a distance metric which uses Euclidean distance for continuous features and 0/1 distance for nominal. Hints:\n",
            "    - Write your own distance function (e.g. mydist) and use clf = KNeighborsClassifier(metric=mydist)\n",
            "    - Change the nominal features in the data set to integer values since KNeighborsClassifier expects numeric features. I used Label_Encoder on the nominal features.\n",
            "    - Keep a list of which features are nominal which mydist can use to decide which distance measure to use\n",
            "    - There was an occasional bug in SK version 1.3.0 (\"Flags object has no attribute 'c_contiguous'\") that went away when I upgraded to the lastest SK version 1.3.1 \n",
            "- Use your own choice for k and other parameters"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 96,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Train Score</th><th style=\"text-align: right;\">  Test Score</th><th style=\"text-align: right;\">  Training MAE</th><th style=\"text-align: right;\">  Testing MAE</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">    0.833333</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">          0.2</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "from sklearn.preprocessing import LabelEncoder\n",
            "# Train/Predict lymph with your own distance metric\n",
            "lymph_data = arff.loadarff('lymph.arff')\n",
            "lymph_df = pd.DataFrame(lymph_data[0])\n",
            "X_lymph = lymph_df.drop('class', axis=1)\n",
            "y_lymph = lymph_df['class']\n",
            "\n",
            "nominal_features = ['lymphatics','block_of_affere', 'bl_of_lymph_c', 'bl_of_lymph_s', 'by_pass', 'extravasates', 'regeneration_of', 'early_uptake_in', 'changes_in_lym', 'defect_in_node', 'changes_in_node', 'changes_in_stru', 'special_forms', 'dislocation_of', 'exclusion_of_no']\n",
            "nominal_indices = []\n",
            "encoder = LabelEncoder()\n",
            "\n",
            "y_lymph = encoder.fit_transform(y_lymph)\n",
            "for feature in nominal_features:\n",
            "    X_lymph[feature] = encoder.fit_transform(X_lymph[feature])\n",
            "    nominal_indices.append(lymph_df.columns.get_loc(feature))\n",
            "\n",
            "    \n",
            "def mydist(point_1, point_2):\n",
            "    distance = 0.0\n",
            "    for feature in range(len(point_1)):\n",
            "        if feature in nominal_indices:\n",
            "            if (point_1[feature] != point_2[feature]):\n",
            "                distance += 1\n",
            "        else:\n",
            "            distance += (point_1[i] - point_2[i])**2\n",
            "    finished_euclidean_distance = np.sqrt(distance)\n",
            "    return finished_euclidean_distance\n",
            "    \n",
            "clf = KNeighborsClassifier(metric=mydist, n_neighbors=3, weights='distance')\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_lymph, y_lymph, test_size=0.2, shuffle=True)\n",
            "table = []\n",
            "clf.fit(X_train, y_train)\n",
            "y_test_pred = clf.predict(X_test)\n",
            "y_train_pred = clf.predict(X_train)\n",
            "\n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test), mean_absolute_error(y_train_pred, y_train), mean_absolute_error(y_test_pred, y_test)])\n",
            "\n",
            "headers = [\"Train Score\", \"Test Score\", \"Training MAE\", \"Testing MAE\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Explain your distance metric and discuss your results*: The distance metric I created, mydist(), takes in two points, point_1 and point_2. For each feature in a given datapoint, the function checks if the feature is nominal. If the feature is nominal, and point_1 and point_2 belong to the same categorization within the nominal feature, then the distance between them in that given feature is 0. If they belong to different categorizations within the same nominal feature, then the distance between them in that feature is a 1. If the feature is continuous rather than nominal, then regular euclidean distance is calculated. Someone with a better knowledge and understanding of the dataset would likely be able to adapt this distance metric so that if any of the nominal features are ordered or similar, the assigned distances from them would reflect this ordering. The model using the metric mydist() obtained a test score of around .8, with a testing mean absolute error of about .2. These results are fairly high when compared to the other KNN models that were used in this lab. However, it is still likely that a different model type would be able to get more accurate results on this data."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 5. (Optional 15% extra credit) Code up your own KNN Learner \n",
            "Below is a scaffold you could use if you want. Requirements for this task:\n",
            "- Your model should support the methods shown in the example scaffold below\n",
            "- Use Euclidean distance to decide closest neighbors\n",
            "- Implement both the classification and regression versions\n",
            "- Include optional distance weighting for both algorithms\n",
            "- Run your algorithm on the magic telescope and housing data sets above and discuss and compare your results "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discussion*"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.base import BaseEstimator, ClassifierMixin\n",
            "\n",
            "class KNNClassifier(BaseEstimator,ClassifierMixin):\n",
            "    def __init__(self, columntype=[], weight_type='inverse_distance'): ## add parameters here\n",
            "        \n",
            "        \"\"\"\n",
            "        Args:\n",
            "            columntype for each column tells you if continues[real] or if nominal[categoritcal].\n",
            "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
            "        \"\"\"\n",
            "        self.columntype = columntype #Note This won't be needed until part 5\n",
            "        self.weight_type = weight_type\n",
            "        self.X = []\n",
            "        self.y = []\n",
            "\n",
            "    def fit(self, data, labels):\n",
            "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
            "            y (array-like): A 2D numpy array with the training targets\n",
            "        Returns:\n",
            "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
            "        \"\"\"\n",
            "        \n",
            "        self.X = data\n",
            "        self.y = labels\n",
            "        return self\n",
            "    \n",
            "    def predict(self, test_set: list):\n",
            "        \"\"\" Predict all classes for a dataset X\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
            "        Returns:\n",
            "            array, shape (n_samples,)\n",
            "                Predicted target values per element in X.\n",
            "        \"\"\"\n",
            "        def calculate_distance(point_1, point_2):\n",
            "            distance_between_points = 0\n",
            "            for i in range(len(point_1)):\n",
            "                distance_between_points += (point_1[i] - point_2[i])**2\n",
            "            return np.sqrt(distance_between_points)\n",
            "            \n",
            "        for example in test_set:\n",
            "            distances = []\n",
            "            votes = []\n",
            "            for i, point in enumerate(self.X):\n",
            "                distances.append((calculate_distance(example, point), self.y[i]))\n",
            "            sorted(distances, key=lambda x: x[1])\n",
            "            nearest_neighbors = distances[:3]\n",
            "\n",
            "            if self.weight_type == 'inverse_distance':\n",
            "                 \n",
            "            \n",
            "            else:\n",
            "                for neighbor in nearest_neighbors:\n",
            "                    votes.append(neighbor[1])\n",
            "                assigned_value = max(set(votes), key=votes.count)\n",
            "\n",
            "        for neighbor in nearest_neighbors:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "        \n",
            "\n",
            "\n",
            "    #Returns the Mean score given input data and labels\n",
            "    def score(self, X, y):\n",
            "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with data, excluding targets\n",
            "            y (array-like): A 2D numpy array with targets\n",
            "        Returns:\n",
            "            score : float\n",
            "                Mean accuracy of self.predict(X) wrt. y.\n",
            "        \"\"\"\n",
            "        return 0"
         ]
      }
   ],
   "metadata": {
      "colab": {
         "collapsed_sections": [],
         "name": "lab 1 - perceptron",
         "provenance": []
      },
      "kernelspec": {
         "display_name": "Python 3.10.7 64-bit",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.5"
      },
      "vscode": {
         "interpreter": {
            "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
