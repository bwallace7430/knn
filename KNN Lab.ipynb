{
   "cells": [
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "DVL7_bgmIAPR"
         },
         "source": [
            "# K-Nearest Neighbor Lab\n",
            "Read over the sklearn info on [nearest neighbor learners](https://scikit-learn.org/stable/modules/neighbors.html#nearest-neighbors-classification)\n",
            "\n",
            "\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {
            "id": "6ZbYjZZZ_yLV"
         },
         "outputs": [],
         "source": [
            "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "from scipy.io import arff\n",
            "import matplotlib.pyplot as plt\n",
            "from sklearn.model_selection import train_test_split"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 1 K-Nearest Neighbor (KNN) algorithm\n",
            "\n",
            "### 1.1 (15%) Basic KNN Classification\n",
            "\n",
            "Learn the [Glass data set](https://archive.ics.uci.edu/dataset/42/glass+identification) using [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) with default parameters.\n",
            "- Randomly split your data into train/test.  Anytime we don't tell you specifics (such as what percentage is train vs test) choose your own reasonable values\n",
            "- Give typical train and test set accuracies after running with different random splits\n",
            "- Print the output probabilities for a test set (predict_proba)\n",
            "- Try it with different p values (Minkowskian exponent) and discuss any differences"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.906977</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.996491</td><td style=\"text-align: right;\">       0.97907 </td><td style=\"text-align: right;\">        1</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.4 0.6]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.4 0.6 0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.8 0.2 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.2 0.8 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.991228</td><td style=\"text-align: right;\">       0.988372</td><td style=\"text-align: right;\">      1.2</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.8 0.2]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.6 0.4 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.2 0.8]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.2 0.8 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.991813</td><td style=\"text-align: right;\">       0.988372</td><td style=\"text-align: right;\">      1.4</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.2 0.8 0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.6 0.4 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.2 0.8 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.991813</td><td style=\"text-align: right;\">       0.983721</td><td style=\"text-align: right;\">      1.6</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  1.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.4 0.6 0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.6 0.4 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.2 0.8]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.4 0.6 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.953488</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.992398</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">      1.8</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.6 0.4]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.2 0.8 0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.6 0.4 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.4 0.6 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]]\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Trial  </th><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th><th style=\"text-align: right;\">  P_Value</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>1      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>2      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>3      </td><td style=\"text-align: right;\">           0.976608</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>4      </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>5      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.906977</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>6      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>7      </td><td style=\"text-align: right;\">           0.982456</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>8      </td><td style=\"text-align: right;\">           0.994152</td><td style=\"text-align: right;\">       1       </td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>9      </td><td style=\"text-align: right;\">           1       </td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>10     </td><td style=\"text-align: right;\">           0.988304</td><td style=\"text-align: right;\">       0.976744</td><td style=\"text-align: right;\">         </td></tr>\n",
                     "<tr><td>Average</td><td style=\"text-align: right;\">           0.989474</td><td style=\"text-align: right;\">       0.974419</td><td style=\"text-align: right;\">        2</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Output probabilities for a test set: [[0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.8 0.2]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.2 0.8 0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.6 0.4 0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  1.  0.  0. ]\n",
                  " [0.  0.  1.  0.  0.  0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.2 0.8 0. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]\n",
                  " [0.  0.  0.  0.  0.  1. ]\n",
                  " [1.  0.  0.  0.  0.  0. ]\n",
                  " [0.  1.  0.  0.  0.  0. ]]\n"
               ]
            }
         ],
         "source": [
            "from IPython.display import HTML, display\n",
            "from tabulate import tabulate\n",
            "\n",
            "# Learn the glass data\n",
            "glass_df = pd.read_csv(\"glass.data\")\n",
            "\n",
            "#extract features X and target variables y\n",
            "X_glass = glass_df.drop('type', axis=1)\n",
            "y_glass = glass_df['type']\n",
            "\n",
            "clf = KNeighborsClassifier()\n",
            "\n",
            "def analyze_model(clf: KNeighborsClassifier, p_value):\n",
            "    table = []\n",
            "    avg_test_acc = 0\n",
            "    avg_train_acc = 0\n",
            "\n",
            "    clf.set_params(p=p_value)\n",
            "    for i in range (0,10):\n",
            "        X_train, X_test, y_train, y_test = train_test_split(X_glass, y_glass, test_size=0.2, shuffle=True)\n",
            "        clf.fit(X_train, y_train) \n",
            "        \n",
            "        table.append([i+1, clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "        avg_train_acc += clf.score(X_train, y_train)\n",
            "        avg_test_acc += clf.score(X_test, y_test)\n",
            "        \n",
            "    avg_train_acc = avg_train_acc/10\n",
            "    avg_test_acc = avg_test_acc/10\n",
            "\n",
            "    #print averages\n",
            "    table.append([\"Average\", avg_train_acc, avg_test_acc, p_value])\n",
            "    headers = [\"Trial\", \"Training Accuracy\", \"Test Accuracy\", \"P_Value\"]\n",
            "    display(HTML(tabulate(table, headers=headers, tablefmt='html')))\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_glass, y_glass, test_size=0.2, shuffle=True)\n",
            "clf.fit(X_train, y_train) \n",
            "\n",
            "analyze_model(clf, 1.0)\n",
            "clf.set_params(p=1.0)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.2)\n",
            "clf.set_params(p=1.2)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.4)\n",
            "clf.set_params(p=1.4)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.6)\n",
            "clf.set_params(p=1.6)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 1.8)\n",
            "clf.set_params(p=1.8)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))\n",
            "\n",
            "analyze_model(clf, 2.0)\n",
            "clf.set_params(p=2.0)\n",
            "print(\"Output probabilities for a test set: \" + str(clf.predict_proba(X_test)))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Discussion: The test accuracies were generally highest with a Minkowskian exponent of around 1.0 or 1.2. In the tests that I ran above, the average test set accuracy for a Minkowskian exponent of 1.0 was 0.988372, while for an exponent of 1.2 it was 0.97907. This makes sense because the Minkowskian exponent is a metric that shifts how the distance is measured, with 1.0 being Manhatten distance (which is generally more robust to noise), and 2.0 being Euclidean distance, which gives extra weight to outliers and noise, and so is not as robust. The output probabilities were also interesting to compare. There were often split output probabilities that two or three of the models would agree on, while the others would not. My hypothesis is that this is just a question of how the math boils down for each measurement of distance. Because the Minkowskian exponent is different for each model, there will naturally be some measurements of distance that will turn out differently for some models than for others."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "9vWiTdlbR2Xh"
         },
         "source": [
            "## 2 KNN Classification with normalization and distance weighting\n",
            "\n",
            "Use the [magic telescope](https://axon.cs.byu.edu/data/uci_class/MagicTelescope.arff) dataset\n",
            "\n",
            "### 2.1 (5%) - Without Normalization or Distance Weighting\n",
            "- Do random 80/20 train/test splits each time\n",
            "- Run with k=3 and *without* distance weighting and *without* normalization\n",
            "- Show train and test set accuracy"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {
            "id": "4SSoasDQSKXb"
         },
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">           0.882558</td><td style=\"text-align: right;\">       0.799685</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Learn magic telescope data\n",
            "telescope_data = arff.loadarff('telescope.arff')\n",
            "telescope_df = pd.DataFrame(telescope_data[0])\n",
            "\n",
            "X_telescope = telescope_df.drop('class:', axis=1)\n",
            "y_telescope = telescope_df['class:']\n",
            "y_telescope = pd.get_dummies(y_telescope)\n",
            "\n",
            "clf = KNeighborsClassifier(weights='uniform', n_neighbors=3)\n",
            "\n",
            "table = []\n",
            "\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_telescope, y_telescope, test_size=0.2, shuffle=True)\n",
            "clf.fit(X_train, y_train)\n",
            "        \n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "headers = [\"Training Accuracy\", \"Test Accuracy\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discussion* This model had a fairly low test accuracy score of around .8, which is not surprising to me. Our k value is fairly low, and we are running this without distance weighting, which means that the three closest points are being considered equally, regardless of how far away they may be. Our data is also not normalized. This means that large-scale numerical features (such as the attribute fDist, which ranges into the hundreds) have a very significant effect on our calculations of distance, while our small-scale features have next to no effect on distance. This means that if a small-scale feature is more indicative than a large-scale feature, it will still not be considered in the classification of a point, because the nearest neighbors will be those that have the smallest distance in the large-scale features only."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 2.2 (10%) With Normalization\n",
            "- Try it with k=3 without distance weighting but *with* normalization of input features.  You may use any reasonable normalization approach (e.g. standard min-max normalization between 0-1, z-transform, etc.)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">           0.902471</td><td style=\"text-align: right;\">       0.820189</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "from sklearn.preprocessing import MinMaxScaler\n",
            "\n",
            "# Train/Predict with normalization\n",
            "scaler = MinMaxScaler()\n",
            "X_normalized = scaler.fit_transform(X_telescope)\n",
            "\n",
            "table = []\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_telescope, test_size=0.2, shuffle=True)\n",
            "clf.fit(X_train, y_train)\n",
            "        \n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "headers = [\"Training Accuracy\", \"Test Accuracy\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))\n"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discuss the results of using normalized data vs. unnormalized data* Normalizing the data did increase the test set accuracy from around .8 to about .83. However, this is a much smaller improvement than I would have expected, given how large some of the features in the telescope are measured. My assumption is that the improvement was relatively small because the originally large-scaled features in the dataset were highly indicative of class, or because the combination of the small-scaled features and large-scaled features still led to the same nearest neighbors being picked. This means that even when the small-scaled features got a more even influence on the distance between points, it did not greatly change the way that the distances were calculated, and the nearest neighbors chosen resulted in about the same accuracy of classification."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 2.3 (10%) With Distance Weighting\n",
            "- Try it with k=3 and with distance weighting *and* normalization"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Training Accuracy</th><th style=\"text-align: right;\">  Test Accuracy</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">       0.824132</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "#Train/Predict with normalization and distance weighting\n",
            "table = []\n",
            "clf.set_params(n_neighbors=3, weights='distance')\n",
            "clf.fit(X_train, y_train)\n",
            "        \n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test)])\n",
            "headers = [\"Training Accuracy\", \"Test Accuracy\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Comparison and Discussion: The model is getting the exact same accuracy as the model with the normalization but without this distance weighting. Although it is possible that the points classified correctly are different points from those classified correctly by the model that just used normalization, I find this unlikely. The models are k=3 models, which means there would need to be at least 2 neighbors that contribute to any misclassification. Unless there is a fairly large difference in the distances of the misclassifying neighbors and the distance of any correctly classifying neighbor, with the misclassifying neighbors being much further from the point of interest than the correctly classifying neighbor, the misclassifying points will have more influence, as there are more of them at a roughly similar distance as the correctly classifying point."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 2.4 (10%) Different k Values\n",
            "- Using your normalized data with distance weighting, create one graph with classification accuracy on the test set on the y-axis and k values on the x-axis.\n",
            "- Use values of k from 1 to 15.  Use the same train/test split for each. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Calculate and Graph classification accuracy vs k values\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_telescope, test_size=0.2, shuffle=True)\n",
            "\n",
            "accuracies = []\n",
            "k_values = []\n",
            "\n",
            "for i in range(0, 15):\n",
            "    k = i + 1\n",
            "    clf.set_params(n_neighbors=k, weights='distance')\n",
            "    clf.fit(X_train, y_train)\n",
            "    k_values.append(k)\n",
            "    accuracies.append(clf.score(X_test, y_test))\n",
            "\n",
            "plt.plot(k_values, accuracies, label='K-Value vs Accuracy')\n",
            "plt.title(\"K-Value vs Accuracy\")\n",
            "plt.xlabel(\"K-Value\")\n",
            "plt.ylabel(\"Accuracy\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discussion*: The accuracy generally improved as more nearest neighbors were taken into account, with the k=15 model getting the highest accuracy score of around .848. However, this is still a fairly low score, which can be explained in a couple different ways. The dataset could have a feature or multiple features that are not indicative of class. These features will still be taken into account in equal measure with the features that are indicative of class, which could cause dissimilar points to be nearest neighbors with one another, leading to misclassification. Another factor in the low accuracy could be a large number of noisy datapoints or outliers, which can act as misclassifying nearest neighbors that contribute to a low classification accuracy for the model as an overall whole."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {
            "id": "SIRG42TgSR4x"
         },
         "source": [
            "## 3 KNN Regression with normalization and distance weighting\n",
            "\n",
            "Use the [sklean KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) on the [housing price prediction](https://axon.cs.byu.edu/data/uci_regression/housing.arff) problem.  \n",
            "### 3.1 (5%) Ethical Data\n",
            "Note this data set has an example of an inappropriate input feature which we discussed.  State which feature is inappropriate and discuss why."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discuss the innapropriate feature*: The feature B is an inappropriate input feature that measures the proportion of black people that live in the area of the house of interest. This feature is inappropriate for a number of reasons, and can have extremely negative impacts in the ethicality of the model. The feature is inappropriate because it may cause the model to pick up on and adopt racist beliefs or methodologies that are unethical and should not have any practical influence on the price of a house. If a model trained on this feature is used in an official capacity, it has the potential to increase divisions of racism and classism, and could have immoral effects on the socio-economic makeup of an area due to race."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 3.2 (15%) - KNN Regression \n",
            "- Do random 80/20 train/test splits each time\n",
            "- Run with k=3\n",
            "- Print the score (coefficient of determination) and Mean Absolute Error (MAE) for the train and test set for the cases of\n",
            "  - No input normalization and no distance weighting\n",
            "  - Normalization and no distance weighting\n",
            "  - Normalization and distance weighting\n",
            "- Normalize inputs features where needed but do not normalize the output"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {
            "id": "KBGUn43ASiXW"
         },
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th>Type                          </th><th style=\"text-align: right;\">  Train Score</th><th style=\"text-align: right;\">  Test Score</th><th style=\"text-align: right;\">  Training MAE</th><th style=\"text-align: right;\">  Testing MAE</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td>No Normalization or Weighting </td><td style=\"text-align: right;\">     0.762131</td><td style=\"text-align: right;\">    0.525324</td><td style=\"text-align: right;\">       3.08317</td><td style=\"text-align: right;\">      3.81275</td></tr>\n",
                     "<tr><td>Normalization and No Weighting</td><td style=\"text-align: right;\">     0.889524</td><td style=\"text-align: right;\">    0.847746</td><td style=\"text-align: right;\">       2.00677</td><td style=\"text-align: right;\">      2.66438</td></tr>\n",
                     "<tr><td>Normalization and Weighting   </td><td style=\"text-align: right;\">     1       </td><td style=\"text-align: right;\">    0.832264</td><td style=\"text-align: right;\">       0      </td><td style=\"text-align: right;\">      2.48249</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "from sklearn.metrics import mean_absolute_error\n",
            "\n",
            "# Learn and experiment with housing price prediction data\n",
            "housing_data = arff.loadarff('housing.arff')\n",
            "housing_df = pd.DataFrame(housing_data[0])\n",
            "X_housing = housing_df.drop('MEDV', axis=1)\n",
            "y_housing = housing_df['MEDV']\n",
            "\n",
            "table = []\n",
            "\n",
            "def train_model(type, X, y, table:list, param='uniform') -> list:\n",
            "    reg = KNeighborsRegressor(n_neighbors=3, weights=param)\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
            "    reg.fit(X_train, y_train)\n",
            "    y_train_pred = reg.predict(X_train)\n",
            "    y_test_pred = reg.predict(X_test)\n",
            "    table.append([type, reg.score(X_train, y_train), reg.score(X_test, y_test), mean_absolute_error(y_train, y_train_pred), mean_absolute_error(y_test, y_test_pred)])\n",
            "    return table\n",
            "\n",
            "table = train_model(\"No Normalization or Weighting\", X_housing, y_housing, table)\n",
            "\n",
            "scaler = MinMaxScaler()\n",
            "X_normalized = scaler.fit_transform(X_housing)\n",
            "table = train_model(\"Normalization and No Weighting\", X_normalized, y_housing, table)\n",
            "\n",
            "table = train_model(\"Normalization and Weighting\", X_normalized, y_housing, table, 'distance')\n",
            "\n",
            "\n",
            "headers = [\"Type\", \"Train Score\", \"Test Score\", \"Training MAE\", \"Testing MAE\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discuss your results*: The normalization and distance weighting helped dramatically with this dataset, much as I had expected from the earlier telescope dataset. The original test score was around .46. After normalization, the score had improved to .76, and after including distance weighting the score had improved again to .84. In the final model, the testing mean absolute error was only 2.388. Although this error is not insignificant, it is around half of the mean absolute error from the test set in the first model, which was about 4.78. This is likely because there were large-scale features that influenced the set dramatically before normalization. "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "### 3.3 (10%)  Different k Values\n",
            "- Using housing with normalized data and distance weighting, create one graph with MAE on the test set on the y-axis and k values on the x-axis\n",
            "- Use values of k from 1 to 15.  Use the same train/test split for each. "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 640x480 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# Learn and graph for different k values\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_housing, test_size=0.2, shuffle=True)\n",
            "reg = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
            "\n",
            "accuracies = []\n",
            "k_values = []\n",
            "\n",
            "for i in range(0, 15):\n",
            "    k = i + 1\n",
            "    reg.set_params(n_neighbors=k)\n",
            "    reg.fit(X_train, y_train)\n",
            "    y_test_pred = reg.predict(X_test)\n",
            "    k_values.append(k)\n",
            "    accuracies.append(mean_absolute_error(y_test, y_test_pred))\n",
            "\n",
            "plt.plot(k_values, accuracies, label='K-Value vs. MAE')\n",
            "plt.title(\"K-Value vs. MAE\")\n",
            "plt.xlabel(\"K-Value\")\n",
            "plt.ylabel(\"MAE\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Discussion: The MAE generally grew as the value of k grew. It reached a minimum when the k value was around 2 or 3, then grew after that. This makes sense, because the true value of any given point is a continuous value. This means that as points are further and further from the point of interest and are given a say in what the value should be, they will drag the predicted value further and further away from where it should be. This is different from classification, in which points do not become more drastically different the further they are from the point of interest. They may be a different class, but there is no gradient of difference that the points are located on."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 4. (20%) KNN with nominal and real data\n",
            "\n",
            "- Use the [lymph dataset](https://axon.cs.byu.edu/data/uci_class/lymph.arff)\n",
            "- Use a 80/20 split of the data for the training/test set\n",
            "- This dataset has both continuous and nominal attributes \n",
            "- Implement a distance metric which uses Euclidean distance for continuous features and 0/1 distance for nominal. Hints:\n",
            "    - Write your own distance function (e.g. mydist) and use clf = KNeighborsClassifier(metric=mydist)\n",
            "    - Change the nominal features in the data set to integer values since KNeighborsClassifier expects numeric features. I used Label_Encoder on the nominal features.\n",
            "    - Keep a list of which features are nominal which mydist can use to decide which distance measure to use\n",
            "    - There was an occasional bug in SK version 1.3.0 (\"Flags object has no attribute 'c_contiguous'\") that went away when I upgraded to the lastest SK version 1.3.1 \n",
            "- Use your own choice for k and other parameters"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<table>\n",
                     "<thead>\n",
                     "<tr><th style=\"text-align: right;\">  Train Score</th><th style=\"text-align: right;\">  Test Score</th><th style=\"text-align: right;\">  Training MAE</th><th style=\"text-align: right;\">  Testing MAE</th></tr>\n",
                     "</thead>\n",
                     "<tbody>\n",
                     "<tr><td style=\"text-align: right;\">            1</td><td style=\"text-align: right;\">         0.9</td><td style=\"text-align: right;\">             0</td><td style=\"text-align: right;\">          0.1</td></tr>\n",
                     "</tbody>\n",
                     "</table>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "from sklearn.preprocessing import LabelEncoder\n",
            "# Train/Predict lymph with your own distance metric\n",
            "lymph_data = arff.loadarff('lymph.arff')\n",
            "lymph_df = pd.DataFrame(lymph_data[0])\n",
            "X_lymph = lymph_df.drop('class', axis=1)\n",
            "y_lymph = lymph_df['class']\n",
            "\n",
            "nominal_features = ['lymphatics','block_of_affere', 'bl_of_lymph_c', 'bl_of_lymph_s', 'by_pass', 'extravasates', 'regeneration_of', 'early_uptake_in', 'changes_in_lym', 'defect_in_node', 'changes_in_node', 'changes_in_stru', 'special_forms', 'dislocation_of', 'exclusion_of_no']\n",
            "nominal_indices = []\n",
            "encoder = LabelEncoder()\n",
            "\n",
            "y_lymph = encoder.fit_transform(y_lymph)\n",
            "for feature in nominal_features:\n",
            "    X_lymph[feature] = encoder.fit_transform(X_lymph[feature])\n",
            "    nominal_indices.append(lymph_df.columns.get_loc(feature))\n",
            "\n",
            "    \n",
            "def mydist(point_1, point_2):\n",
            "    distance = 0.0\n",
            "    for feature in range(len(point_1)):\n",
            "        if feature in nominal_indices:\n",
            "            if (point_1[feature] != point_2[feature]):\n",
            "                distance += 1\n",
            "        else:\n",
            "            distance += (point_1[i] - point_2[i])**2\n",
            "    finished_euclidean_distance = np.sqrt(distance)\n",
            "    return finished_euclidean_distance\n",
            "    \n",
            "clf = KNeighborsClassifier(metric=mydist, n_neighbors=3, weights='distance')\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_lymph, y_lymph, test_size=0.2, shuffle=True)\n",
            "table = []\n",
            "clf.fit(X_train, y_train)\n",
            "y_test_pred = clf.predict(X_test)\n",
            "y_train_pred = clf.predict(X_train)\n",
            "\n",
            "table.append([clf.score(X_train, y_train), clf.score(X_test, y_test), mean_absolute_error(y_train_pred, y_train), mean_absolute_error(y_test_pred, y_test)])\n",
            "\n",
            "headers = [\"Train Score\", \"Test Score\", \"Training MAE\", \"Testing MAE\"]\n",
            "display(HTML(tabulate(table, headers=headers, tablefmt='html')))"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Explain your distance metric and discuss your results*: The distance metric I created, mydist(), takes in two points, point_1 and point_2. For each feature in a given datapoint, the function checks if the feature is nominal. If the feature is nominal, and point_1 and point_2 belong to the same categorization within the nominal feature, then the distance between them in that given feature is 0. If they belong to different categorizations within the same nominal feature, then the distance between them in that feature is a 1. If the feature is continuous rather than nominal, then regular euclidean distance is calculated. Someone with a better knowledge and understanding of the dataset would likely be able to adapt this distance metric so that if any of the nominal features are ordered or similar, the assigned distances from them would reflect this ordering. The model using the metric mydist() obtained a test score of around .8, with a testing mean absolute error of about .2. These results are fairly high when compared to the other KNN models that were used in this lab. However, it is still likely that a different model type would be able to get more accurate results on this data."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 5. (Optional 15% extra credit) Code up your own KNN Learner \n",
            "Below is a scaffold you could use if you want. Requirements for this task:\n",
            "- Your model should support the methods shown in the example scaffold below\n",
            "- Use Euclidean distance to decide closest neighbors\n",
            "- Implement both the classification and regression versions\n",
            "- Include optional distance weighting for both algorithms\n",
            "- Run your algorithm on the magic telescope and housing data sets above and discuss and compare your results "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "*Discussion*: The accuracy of my model was far lower than the regular KNeighborsClassifier and KNeighborsRegressor in scikitlearn. I'm not sure why that is, but I would suspect that it has something to do with my weighting or scoring metrics. In class we discussed many different weighting metrics, with the most common being inverse squared weighting. I didn't implement this version in my model, but rather used pure inverse weighting. This likely influenced the outcome of my model, resulting in a lower accuracy. It is also possible that the scoring methods were different. For example, in my regressor I used sum squared error, while the KNeighborsRegressor uses mean absolute error. Because of this, there will be some natural differences in the appearance of the scores."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 61,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "0.5602523659305993\n"
               ]
            }
         ],
         "source": [
            "from sklearn.base import BaseEstimator, ClassifierMixin\n",
            "import numpy as np\n",
            "\n",
            "class KNNClassifier(BaseEstimator,ClassifierMixin):\n",
            "    def __init__(self, weight_type='inverse_distance'): ## add parameters here\n",
            "        \n",
            "        \"\"\"\n",
            "        Args:\n",
            "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
            "        \"\"\"\n",
            "        self.weight_type = weight_type\n",
            "        self.X = []\n",
            "        self.y = []\n",
            "\n",
            "    def fit(self, data, labels):\n",
            "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
            "            y (array-like): A 2D numpy array with the training targets\n",
            "        Returns:\n",
            "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
            "        \"\"\"\n",
            "        \n",
            "        self.X = data\n",
            "        self.y = labels.values\n",
            "        return self\n",
            "    \n",
            "    def predict(self, test_set: list):\n",
            "        \"\"\" Predict all classes for a dataset X\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
            "        Returns:\n",
            "            array, shape (n_samples,)\n",
            "                Predicted target values per element in X.\n",
            "        \"\"\"\n",
            "        predictions = []\n",
            "\n",
            "        # euclidean distance function for the distance between two points\n",
            "        def calculate_distance(point_1, point_2):\n",
            "            distance_between_points = 0\n",
            "            for i in range(len(point_1)):\n",
            "            # if point_1 is a continuous feature, add euclidean distance to total distance\n",
            "                if (isinstance(point_1[i], float) or isinstance(point_1[i], int)):\n",
            "                    distance_between_points += (point_1[i] - point_2[i])**2\n",
            "                # if point_1 is a nominal feature and is a different category from point_2, add a distance of 1 to total distance; else add distance of 0\n",
            "                else:\n",
            "                    if point_1[i] != point_2[i]:\n",
            "                        distance_between_points += 1\n",
            "            return np.sqrt(distance_between_points)\n",
            "        \n",
            "        # for each example, find the distances between that example and every point in the stored dataset\n",
            "        for example in test_set:\n",
            "            distances = []\n",
            "            nearest_neighbors = []\n",
            "            for i, point in enumerate(self.X):\n",
            "                distances.append((calculate_distance(example, point), str(self.y[i])))\n",
            "            # sort the distances from lowest to highest and store the three closest points in nearest_neighbors with their respective distances\n",
            "            distances = sorted(distances, key=lambda x: x[0])\n",
            "            nearest_neighbors = distances[:3]\n",
            "\n",
            "            # if doing distance weighting, for each of the three nearest neighbors, calculate an inverse weight (or 1 if the weight is 0)\n",
            "            if self.weight_type == 'inverse_distance':\n",
            "                votes = {}\n",
            "                for neighbor in nearest_neighbors:\n",
            "                    if neighbor[0] == 0:\n",
            "                        weight = 1\n",
            "                    else: \n",
            "                        weight = 1/neighbor[0]\n",
            "                    \n",
            "                    # if the elected class has already been voted for, add this neighbor's vote weight to total; else, add a vote for the elected class\n",
            "                    if neighbor[1] in votes:\n",
            "                        votes[neighbor[1]] += weight\n",
            "                    else:\n",
            "                        votes[neighbor[1]] = weight\n",
            "                \n",
            "                # get the class with the max votes and add to predictions\n",
            "                votes_list = list(votes.items())\n",
            "                assigned_value = max(votes_list, key=lambda x: x[1])\n",
            "                predictions.append(assigned_value)\n",
            "            \n",
            "            # if doing uniform weighting, store all votes and take the most common class and add it to your predictions\n",
            "            else:\n",
            "                votes = []\n",
            "                for neighbor in nearest_neighbors:\n",
            "                    votes.append(neighbor[1])\n",
            "                assigned_value = max(set(votes), key=votes.count)\n",
            "                predictions.append(assigned_value)\n",
            "\n",
            "        return predictions\n",
            "\n",
            "    #Returns the Mean score given input data and labels\n",
            "    def score(self, X, y):\n",
            "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with data, excluding targets\n",
            "            y (array-like): A 2D numpy array with targets\n",
            "        Returns:\n",
            "            score : floats\n",
            "                Mean accuracy of self.predict(X) wrt. y.\n",
            "        \"\"\"\n",
            "\n",
            "        predictions = self.predict(X)\n",
            "        num_correct = 0\n",
            "        for i, prediction in enumerate(predictions):\n",
            "            if (prediction[0] == str(self.y[i])):\n",
            "                num_correct += 1\n",
            "        return num_correct/len(predictions)\n",
            "\n",
            "scaler = MinMaxScaler()\n",
            "X_normalized = scaler.fit_transform(X_telescope)\n",
            "\n",
            "clf = KNNClassifier()\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_telescope)\n",
            "clf.fit(X_train, y_train)\n",
            "print(str(clf.score(X_test, y_test)))"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 60,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "9.824065444804196\n"
               ]
            }
         ],
         "source": [
            "from sklearn.base import BaseEstimator, RegressorMixin\n",
            "\n",
            "class KNNRegressor(BaseEstimator, RegressorMixin):\n",
            "    def __init__(self, columntype=[], weight_type='inverse_distance'):  # add parameters here\n",
            "        \"\"\"\n",
            "        Args:\n",
            "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
            "        \"\"\"\n",
            "        self.weight_type = weight_type\n",
            "        self.X = []\n",
            "        self.y = []\n",
            "\n",
            "    def fit(self, data, labels):\n",
            "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
            "            y (array-like): A 2D numpy array with the training targets\n",
            "        Returns:\n",
            "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
            "        \"\"\"\n",
            "\n",
            "        self.X = data\n",
            "        self.y = labels\n",
            "        return self\n",
            "\n",
            "    def predict(self, test_set: list):\n",
            "        \"\"\" Predict all classes for a dataset X\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
            "        Returns:\n",
            "            array, shape (n_samples,)\n",
            "                Predicted target values per element in X.\n",
            "        \"\"\"\n",
            "        predictions = []\n",
            "\n",
            "        # euclidean distance function for the distance between two points\n",
            "        def calculate_distance(point_1, point_2):\n",
            "            distance_between_points = 0\n",
            "            for i in range(len(point_1)):\n",
            "                distance_between_points += (point_1[i] - point_2[i])**2\n",
            "            return np.sqrt(distance_between_points)\n",
            "\n",
            "        # for each example, find the distances between that example and every point in the stored dataset\n",
            "        for example in test_set:\n",
            "            distances = []\n",
            "            for i, point in enumerate(self.X):\n",
            "                distances.append(\n",
            "                    (calculate_distance(example, point), self.y.iloc[i]))\n",
            "            # sort the distances from lowest to highest and store the three closest points in nearest_neighbors with their respective distances\n",
            "            distances = sorted(distances, key=lambda x: x[0])\n",
            "            nearest_neighbors = distances[:3]\n",
            "\n",
            "            # if doing distance weighting, for each of the three nearest neighbors, calculate an inverse weight (or 1 if the weight is 0)\n",
            "            if self.weight_type == 'inverse_distance':\n",
            "                sum = 0\n",
            "                total_weight = 0\n",
            "                for neighbor in nearest_neighbors:\n",
            "                    if neighbor[0] == 0:\n",
            "                        weight = 1\n",
            "                    else:\n",
            "                        weight = 1/neighbor[0]\n",
            "                    # take the sum of each neighbor's value multiplied by their respective weights\n",
            "                    sum += neighbor[1] * weight\n",
            "                    total_weight += weight\n",
            "                # find the average by dividing the sum by the total combined weights of all points\n",
            "                average = sum/total_weight\n",
            "                predictions.append(average)\n",
            "\n",
            "            # if doing uniform weighting, take the average value of the three neighbors\n",
            "            else:\n",
            "                average = 0\n",
            "                for neighbor in nearest_neighbors:\n",
            "                    average += neighbor[1]\n",
            "                average = average/3\n",
            "                predictions.append(average)\n",
            "\n",
            "        return predictions\n",
            "\n",
            "    # Returns the Mean score given input data and labels\n",
            "    def score(self, X, y):\n",
            "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
            "        Args:\n",
            "            X (array-like): A 2D numpy array with data, excluding targets\n",
            "            y (array-like): A 2D numpy array with targets\n",
            "        Returns:\n",
            "            score : floats\n",
            "                Mean accuracy of self.predict(X) wrt. y.\n",
            "        \"\"\"\n",
            "\n",
            "        sse = 0\n",
            "        predictions = self.predict(X)\n",
            "        for i, prediction in enumerate(predictions):\n",
            "            sse += np.abs((prediction-self.y.iloc[i]))\n",
            "        return sse/len(predictions)\n",
            "\n",
            "# debug_data = arff.loadarff('condensed_housing.arff')\n",
            "# debug_df = pd.DataFrame(debug_data[0])\n",
            "# X_debug = debug_df.drop('MEDV', axis=1)\n",
            "# y_debug = debug_df['MEDV']\n",
            "# scaler = MinMaxScaler()\n",
            "# X_normalized = scaler.fit_transform(X_debug)\n",
            "\n",
            "\n",
            "housing_data = arff.loadarff('housing.arff')\n",
            "housing_df = pd.DataFrame(housing_data[0])\n",
            "X_housing = housing_df.drop('MEDV', axis=1)\n",
            "y_housing = housing_df['MEDV']\n",
            "scaler = MinMaxScaler()\n",
            "X_normalized = scaler.fit_transform(X_housing)\n",
            "\n",
            "clf = KNNRegressor()\n",
            "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y_housing)\n",
            "clf.fit(X_train, y_train)\n",
            "print(str(clf.score(X_test, y_test)))"
         ]
      }
   ],
   "metadata": {
      "colab": {
         "collapsed_sections": [],
         "name": "lab 1 - perceptron",
         "provenance": []
      },
      "kernelspec": {
         "display_name": "Python 3.10.7 64-bit",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.3"
      },
      "vscode": {
         "interpreter": {
            "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
         }
      }
   },
   "nbformat": 4,
   "nbformat_minor": 4
}
